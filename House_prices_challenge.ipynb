{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model with BigML and first submission to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "import bigml.api\n",
    "from bigml.api import BigML\n",
    "#api= BigML (project='project/5d8dbde0eba31d7fc0000865')\n",
    "api=BigML(\n",
    "source = api.create_source('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "api.ok(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_trainfull = api.create_dataset(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.ok(dataset_trainfull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split on trainfull 80/20\n",
    "train_dataset = api.create_dataset(\n",
    "    dataset_trainfull, {\"name\": \"Train80\",\n",
    "                     \"sample_rate\": 0.8, \"seed\": \"my seed\"})\n",
    "val = api.create_dataset(\n",
    "    dataset_trainfull, {\"name\": \"Train20\",\n",
    "                     \"sample_rate\": 0.8, \"seed\": \"my seed\",\n",
    "                     \"out_of_bag\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.ok(train_dataset)\n",
    "api.ok(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deepnet\n",
    "model = api.create_deepnet(train_dataset, {\"objective_field\":\"SalePrice\"})\n",
    "api.ok(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = api.create_evaluation(model, train_dataset)\n",
    "api.ok(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.pprint(evaluation['object']['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear regression\n",
    "linear_regression = api.create_linear_regression(train_dataset)\n",
    "\n",
    "api.ok(linear_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_lr = api.create_evaluation(linear_regression, train_dataset)\n",
    "api.ok(evaluation_lr)\n",
    "api.pprint(evaluation_lr['object']['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction on deepnet model\n",
    "batch_prediction = api.create_batch_prediction(model, val, {\n",
    "    \"all_fields\": True, \"confidence\": True, \"probabilities\": True, \"prediction_name\": \"my_prediction\"})\n",
    "api.ok(batch_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.download_batch_prediction(batch_prediction,\n",
    "    filename='prediction_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_val = read_csv('prediction_val.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation of % Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in [prediction_val]:\n",
    "    row['% Error'] = ((row['my_prediction'] - row['SalePrice'])/row['SalePrice'])*100\n",
    "row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation of Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in [prediction_val]:\n",
    "    row['Error'] = row['my_prediction'] - row['SalePrice']\n",
    "row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation of Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for row in [prediction_val]:\n",
    "    row['Error_ABS'] = abs(row['Error'])\n",
    "row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAE =  mean absolute error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "target_column = 'Error_ABS'\n",
    "a = prediction_val[target_column].values\n",
    "\n",
    "MAE = np.mean(a)\n",
    "\n",
    "MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for row in [prediction_val]:\n",
    "    row['Error_ABS_squared'] = row['Error']*row['Error']\n",
    "row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE = mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'Error_ABS_squared'\n",
    "b = prediction_val[target_column].values\n",
    "\n",
    "MSE = np.mean(b)\n",
    "\n",
    "print(MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_csv = prediction_val.to_csv ('prediction_error.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upload the test\n",
    "test_source = api.create_source('test.csv')\n",
    "api.ok(test_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = api.create_dataset(test_source)\n",
    "api.ok(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deepnet on the trainfull dataset\n",
    "model_2 = api.create_ensemble(dataset_trainfull, {\"objective_field\":\"SalePrice\"})\n",
    "api.ok(model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_prediction_full = api.create_batch_prediction(model_2, dataset_test, {\"all_fields\": True, \"confidence\": True, \"probabilities\": True, \"prediction_name\": \"my_prediction\"})\n",
    "api.ok(batch_prediction_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_full = api.create_evaluation(model_2, dataset_trainfull)\n",
    "api.ok(evaluation_full)\n",
    "api.pprint(evaluation_full['object']['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.download_batch_prediction(batch_prediction_full,\n",
    "    filename='prediction_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the new prediction and remove the columns/replace Id and SalePrice\n",
    "import pandas as pd\n",
    "df = pd.read_csv('prediction_test.csv')\n",
    "shape = df.shape\n",
    "print(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_col = df['Id'].values.tolist()\n",
    "prediction_col = df['my_prediction'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "submission = pd.DataFrame()\n",
    "submission['Id'] = id_col\n",
    "submission['SalePrice'] = prediction_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kaggle\n",
    "kaggle.api.competition_submit(\"submission_1.csv\", \"test\", \"house-prices-advanced-regression-techniques\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = 0.15452\n",
    "print(\"Kaggle Score:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
