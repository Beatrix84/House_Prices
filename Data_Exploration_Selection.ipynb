{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T19:10:13.354996Z",
     "start_time": "2019-11-28T19:10:05.200519Z"
    },
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.preprocessing import StandardScaler # Used for scaling of data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import metrics\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "from keras.wrappers.scikit_learn import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T19:10:13.449999Z",
     "start_time": "2019-11-28T19:10:13.362949Z"
    },
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/train.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T19:10:13.527966Z",
     "start_time": "2019-11-28T19:10:13.454947Z"
    },
    "_uuid": "cb0db41d4fc18a4992301ae08bf61fad4f489f56",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f073ac12db41eb616c7d3116537783d890286afd",
    "collapsed": true
   },
   "source": [
    "# Prepare data\n",
    "    Investigate what data that has a linear or some kind of relation to the sale price\n",
    "    Drop the unimportant features or less unimportant features\n",
    "    Drop features which has many NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T19:10:13.544968Z",
     "start_time": "2019-11-28T19:10:13.530967Z"
    },
    "_uuid": "f41e1f2f85b2beda54623e15555c4aebca349522"
   },
   "outputs": [],
   "source": [
    "#descriptive statistics summary\n",
    "df_train['SalePrice'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T19:10:13.907942Z",
     "start_time": "2019-11-28T19:10:13.546945Z"
    },
    "_uuid": "1cfcee21e591d2e426d3ac9b3d78e96564bfbb87"
   },
   "outputs": [],
   "source": [
    "#histogram\n",
    "sns.distplot(df_train['SalePrice']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T19:10:13.916954Z",
     "start_time": "2019-11-28T19:10:13.909965Z"
    },
    "_uuid": "4d96bb824f0a8b9994a9c312e0032e7fddb2c964"
   },
   "outputs": [],
   "source": [
    "#skewness and kurtosis\n",
    "print(\"Skewness: %f\" % df_train['SalePrice'].skew())\n",
    "print(\"Kurtosis: %f\" % df_train['SalePrice'].kurt())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3e04a673e79b42e251535b523cf4fdd375c948e4"
   },
   "source": [
    "    - Skewness means the top of the iceberg is not in the middle but rather towards left or right.\n",
    "    - Kurtosis describe if the gaussian distrubution is very small and narrow or very wide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b037115d4df4b5a57ab16204e15d954173ffefa0"
   },
   "source": [
    "Use a heatmap to see which features have strongest correlation with price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T19:10:15.125963Z",
     "start_time": "2019-11-28T19:10:13.920964Z"
    },
    "_uuid": "e1b24a67d4ba435393dfe8a94bac1b46bb5b2653"
   },
   "outputs": [],
   "source": [
    "#correlation matrix\n",
    "corrmat = df_train.corr()\n",
    "f, ax = plt.subplots(figsize=(12, 9))\n",
    "sns.heatmap(corrmat, vmax=.8, square=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "69c5af34c8ab83091cfbc91ab77bf3145901b6a6"
   },
   "source": [
    "Here we can detect multicollinearity for example basement area and the area of the first floor so these hold more or less the same kind of data. \n",
    "Some variables are also important for the SalePrice with the biggest one being OverallQual.\n",
    "\n",
    "Plot top 10 most important for correlating with SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T19:10:15.684959Z",
     "start_time": "2019-11-28T19:10:15.128963Z"
    },
    "_uuid": "ef685a7c0285e63735037ff7aff16b58b7aff810"
   },
   "outputs": [],
   "source": [
    "#saleprice correlation matrix\n",
    "k = 10 #number of variables for heatmap\n",
    "cols = corrmat.nlargest(k, 'SalePrice')['SalePrice'].index\n",
    "cm = np.corrcoef(df_train[cols].values.T)\n",
    "sns.set(font_scale=1.25)\n",
    "hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "eb0f81a1f65090603bc258fffed8177ab193a5fe"
   },
   "source": [
    "From this plot we can draw the conclusion that:\n",
    "    - OverallQual is important\n",
    "    - GrLivArea is also important\n",
    "    - TotalBsmtSF is important\n",
    "    - GarageCars and GarageArea are two important features but we drop GarageArea since it is more or less the same information as GarageCars\n",
    "    - TotalBsmtSF and 1stFlrSF are also more or less the same so we drop 1StFlrSF\n",
    "    - TotRmsAbvGrd and GrLivArea are also strongly correlated to let's drop TotRmsAbvGrd\n",
    " \n",
    " Let's scatterplot these important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T19:10:21.334963Z",
     "start_time": "2019-11-28T19:10:15.685942Z"
    },
    "_uuid": "20308da96c6fe321ad8eaa36936b1f4f310e246b"
   },
   "outputs": [],
   "source": [
    "#scatterplot\n",
    "sns.set()\n",
    "cols = ['SalePrice', 'OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt']\n",
    "sns.pairplot(df_train[cols], size = 2.5)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ac7fec49425bb709149872260a913ca04eda50e8"
   },
   "source": [
    "The basement area and total living area seems to have similarities their saleprice plot looks almost identical, let's remove basement area.\n",
    "\n",
    "Maybe also remove year built data since this data can be tricky to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "394c7fab3b8a90176635ef240466257c45b0b549"
   },
   "source": [
    "Let's have a  look at the missing data.\n",
    "\n",
    "Let's display a % of the data that is missing from some columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T19:10:21.359959Z",
     "start_time": "2019-11-28T19:10:21.335964Z"
    },
    "_uuid": "a5f4b941925a23b99e781dc5ce921aa789cbc9a7"
   },
   "outputs": [],
   "source": [
    "#missing data\n",
    "total = df_train.isnull().sum().sort_values(ascending=False)\n",
    "percent = (df_train.isnull().sum()/df_train.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "missing_data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e81bfe548fff5b1a48f1591d25a84f55e6b8b830"
   },
   "source": [
    "Some of theese features are of interest for us and they don't show a massive shortage of data so lets create mean data for those values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T19:10:21.501948Z",
     "start_time": "2019-11-28T19:10:21.360945Z"
    },
    "_uuid": "a16226a47ed6d2fec9a6e69d8f7d982e4589e1e1"
   },
   "outputs": [],
   "source": [
    "df_train = df_train.fillna(df_train.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5d2f7b9502cb2cccc0f34642a042a227f703fddd"
   },
   "source": [
    "Now let's remove outliers for example data that doesn't match what we expect like an insane price for a house\n",
    "\n",
    "To do this we standardize the data so that the mean is 0 and a standard deviation of 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T19:10:21.510943Z",
     "start_time": "2019-11-28T19:10:21.502955Z"
    },
    "_uuid": "5fd1ebd08dc93d5b68d519ac7d2b695b212612f1"
   },
   "outputs": [],
   "source": [
    "#standardizing data\n",
    "saleprice_scaled = StandardScaler().fit_transform(df_train['SalePrice'][:,np.newaxis]);\n",
    "low_range = saleprice_scaled[saleprice_scaled[:,0].argsort()][:10]\n",
    "high_range= saleprice_scaled[saleprice_scaled[:,0].argsort()][-10:]\n",
    "print('outer range (low) of the distribution:')\n",
    "print(low_range)\n",
    "print('\\nouter range (high) of the distribution:')\n",
    "print(high_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "91fc3e063f9fc40b36aee72864be793171f62f32"
   },
   "source": [
    "    -Values that are similar to each other stay close to 0\n",
    "    -Values that are a bit odd get high values such as the 7 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T19:10:21.703943Z",
     "start_time": "2019-11-28T19:10:21.512950Z"
    },
    "_uuid": "a9ce9e94821aaa869a66174feff34e4fb7b0a96f"
   },
   "outputs": [],
   "source": [
    "#bivariate analysis saleprice/grlivarea\n",
    "var = 'GrLivArea'\n",
    "data = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\n",
    "data.plot.scatter(x=var, y='SalePrice', ylim=(0,800000));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bivariate analysis saleprice/grlivarea\n",
    "var = 'OverallQual'\n",
    "data = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\n",
    "data.plot.scatter(x=var, y='SalePrice', ylim=(0,800000));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bivariate analysis saleprice/grlivarea\n",
    "var = 'GarageCars'\n",
    "data = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\n",
    "data.plot.scatter(x=var, y='SalePrice', ylim=(0,800000));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bivariate analysis saleprice/grlivarea\n",
    "var = 'FullBath'\n",
    "data = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\n",
    "data.plot.scatter(x=var, y='SalePrice', ylim=(0,800000));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bivariate analysis saleprice/grlivarea\n",
    "var = 'YearBuilt'\n",
    "data = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\n",
    "data.plot.scatter(x=var, y='SalePrice', ylim=(0,800000));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['SalePrice','OverallQual', 'GrLivArea', 'GarageCars', 'FullBath', 'YearBuilt']\n",
    "df_train = df_train[cols]\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_csv = df_train.to_csv (r'./Data/trainfull_exploration_selection.csv', header=True)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
