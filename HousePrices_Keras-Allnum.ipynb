{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.preprocessing import StandardScaler # Used for scaling of data\n",
    "from keras import metrics\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in train data\n",
    "trainfull = pd.read_csv('../HousePrices/trainfull.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainfull = trainfull.select_dtypes(exclude=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>192</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1456</td>\n",
       "      <td>60</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1999</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1457</td>\n",
       "      <td>20</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1978</td>\n",
       "      <td>1988</td>\n",
       "      <td>119.0</td>\n",
       "      <td>790</td>\n",
       "      <td>163</td>\n",
       "      <td>...</td>\n",
       "      <td>349</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1458</td>\n",
       "      <td>70</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1941</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>275</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>266500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1459</td>\n",
       "      <td>20</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1950</td>\n",
       "      <td>1996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49</td>\n",
       "      <td>1029</td>\n",
       "      <td>...</td>\n",
       "      <td>366</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>142125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1460</td>\n",
       "      <td>20</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1965</td>\n",
       "      <td>1965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>830</td>\n",
       "      <td>290</td>\n",
       "      <td>...</td>\n",
       "      <td>736</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>147500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "Id                                                                            \n",
       "1             60         65.0     8450            7            5       2003   \n",
       "2             20         80.0     9600            6            8       1976   \n",
       "3             60         68.0    11250            7            5       2001   \n",
       "4             70         60.0     9550            7            5       1915   \n",
       "5             60         84.0    14260            8            5       2000   \n",
       "...          ...          ...      ...          ...          ...        ...   \n",
       "1456          60         62.0     7917            6            5       1999   \n",
       "1457          20         85.0    13175            6            6       1978   \n",
       "1458          70         66.0     9042            7            9       1941   \n",
       "1459          20         68.0     9717            5            6       1950   \n",
       "1460          20         75.0     9937            5            6       1965   \n",
       "\n",
       "      YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  WoodDeckSF  \\\n",
       "Id                                                      ...               \n",
       "1             2003       196.0         706           0  ...           0   \n",
       "2             1976         0.0         978           0  ...         298   \n",
       "3             2002       162.0         486           0  ...           0   \n",
       "4             1970         0.0         216           0  ...           0   \n",
       "5             2000       350.0         655           0  ...         192   \n",
       "...            ...         ...         ...         ...  ...         ...   \n",
       "1456          2000         0.0           0           0  ...           0   \n",
       "1457          1988       119.0         790         163  ...         349   \n",
       "1458          2006         0.0         275           0  ...           0   \n",
       "1459          1996         0.0          49        1029  ...         366   \n",
       "1460          1965         0.0         830         290  ...         736   \n",
       "\n",
       "      OpenPorchSF  EnclosedPorch  3SsnPorch  ScreenPorch  PoolArea  MiscVal  \\\n",
       "Id                                                                            \n",
       "1              61              0          0            0         0        0   \n",
       "2               0              0          0            0         0        0   \n",
       "3              42              0          0            0         0        0   \n",
       "4              35            272          0            0         0        0   \n",
       "5              84              0          0            0         0        0   \n",
       "...           ...            ...        ...          ...       ...      ...   \n",
       "1456           40              0          0            0         0        0   \n",
       "1457            0              0          0            0         0        0   \n",
       "1458           60              0          0            0         0     2500   \n",
       "1459            0            112          0            0         0        0   \n",
       "1460           68              0          0            0         0        0   \n",
       "\n",
       "      MoSold  YrSold  SalePrice  \n",
       "Id                               \n",
       "1          2    2008     208500  \n",
       "2          5    2007     181500  \n",
       "3          9    2008     223500  \n",
       "4          2    2006     140000  \n",
       "5         12    2008     250000  \n",
       "...      ...     ...        ...  \n",
       "1456       8    2007     175000  \n",
       "1457       2    2010     210000  \n",
       "1458       5    2010     266500  \n",
       "1459       4    2010     142125  \n",
       "1460       6    2008     147500  \n",
       "\n",
       "[1460 rows x 37 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainfull.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import random\n",
    "SEED = 42\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "VAL_SIZE = 0.2\n",
    "train, val = train_test_split(trainfull, test_size=VAL_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.fillna(0)\n",
    "val = val.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_train_bis = list(train.columns)\n",
    "col_train_bis.remove('SalePrice')\n",
    "Features = col_train_bis\n",
    "X_train = train[Features]\n",
    "X_val = val[Features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['SalePrice'].values\n",
    "y_val = val['SalePrice'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/tf2/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/opt/conda/envs/tf2/lib/python3.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "scale = StandardScaler()\n",
    "X_train = scale.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/tf2/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/opt/conda/envs/tf2/lib/python3.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "scale = StandardScaler()\n",
    "X_val = scale.fit_transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1168/1168 [==============================] - 0s 405us/step - loss: 181441.5423\n",
      "Epoch 2/150\n",
      "1168/1168 [==============================] - 0s 289us/step - loss: 181441.5419\n",
      "Epoch 3/150\n",
      "1168/1168 [==============================] - 0s 283us/step - loss: 181441.5419\n",
      "Epoch 4/150\n",
      "1168/1168 [==============================] - 0s 285us/step - loss: 181441.5420\n",
      "Epoch 5/150\n",
      "1168/1168 [==============================] - 0s 284us/step - loss: 181441.5420\n",
      "Epoch 6/150\n",
      "1168/1168 [==============================] - 0s 283us/step - loss: 181441.5416\n",
      "Epoch 7/150\n",
      "1168/1168 [==============================] - 0s 289us/step - loss: 181441.5419\n",
      "Epoch 8/150\n",
      "1168/1168 [==============================] - 0s 283us/step - loss: 181441.5410\n",
      "Epoch 9/150\n",
      "1168/1168 [==============================] - 0s 290us/step - loss: 181441.5387\n",
      "Epoch 10/150\n",
      "1168/1168 [==============================] - 0s 280us/step - loss: 181441.5365\n",
      "Epoch 11/150\n",
      "1168/1168 [==============================] - 0s 288us/step - loss: 181441.5343\n",
      "Epoch 12/150\n",
      "1168/1168 [==============================] - 0s 288us/step - loss: 181441.5320\n",
      "Epoch 13/150\n",
      "1168/1168 [==============================] - 0s 280us/step - loss: 181441.5291\n",
      "Epoch 14/150\n",
      "1168/1168 [==============================] - 0s 291us/step - loss: 181441.5244\n",
      "Epoch 15/150\n",
      "1168/1168 [==============================] - 0s 282us/step - loss: 181441.5205\n",
      "Epoch 16/150\n",
      "1168/1168 [==============================] - 0s 282us/step - loss: 181441.5168\n",
      "Epoch 17/150\n",
      "1168/1168 [==============================] - 0s 287us/step - loss: 181441.5148\n",
      "Epoch 18/150\n",
      "1168/1168 [==============================] - 0s 284us/step - loss: 181441.5145\n",
      "Epoch 19/150\n",
      "1168/1168 [==============================] - 0s 283us/step - loss: 181441.5136\n",
      "Epoch 20/150\n",
      "1168/1168 [==============================] - 0s 281us/step - loss: 181441.5129\n",
      "Epoch 21/150\n",
      "1168/1168 [==============================] - 0s 280us/step - loss: 181441.5127\n",
      "Epoch 22/150\n",
      "1168/1168 [==============================] - 0s 283us/step - loss: 181441.5127\n",
      "Epoch 23/150\n",
      "1168/1168 [==============================] - 0s 288us/step - loss: 181441.5121\n",
      "Epoch 24/150\n",
      "1168/1168 [==============================] - 0s 283us/step - loss: 181441.5120\n",
      "Epoch 25/150\n",
      "1168/1168 [==============================] - 0s 298us/step - loss: 181441.5119\n",
      "Epoch 26/150\n",
      "1168/1168 [==============================] - 0s 278us/step - loss: 181441.5115\n",
      "Epoch 27/150\n",
      "1168/1168 [==============================] - 0s 290us/step - loss: 181441.5102\n",
      "Epoch 28/150\n",
      "1168/1168 [==============================] - 0s 282us/step - loss: 181441.5086\n",
      "Epoch 29/150\n",
      "1168/1168 [==============================] - 0s 284us/step - loss: 181441.5029\n",
      "Epoch 30/150\n",
      "1168/1168 [==============================] - 0s 280us/step - loss: 181441.4949\n",
      "Epoch 31/150\n",
      "1168/1168 [==============================] - 0s 283us/step - loss: 181441.4878\n",
      "Epoch 32/150\n",
      "1168/1168 [==============================] - 0s 286us/step - loss: 181441.4833\n",
      "Epoch 33/150\n",
      "1168/1168 [==============================] - 0s 280us/step - loss: 181441.4819\n",
      "Epoch 34/150\n",
      "1168/1168 [==============================] - 0s 283us/step - loss: 181441.4817\n",
      "Epoch 35/150\n",
      "1168/1168 [==============================] - 0s 283us/step - loss: 181441.4803\n",
      "Epoch 36/150\n",
      "1168/1168 [==============================] - 0s 279us/step - loss: 181441.4784\n",
      "Epoch 37/150\n",
      "1168/1168 [==============================] - 0s 293us/step - loss: 181441.4763\n",
      "Epoch 38/150\n",
      "1168/1168 [==============================] - 0s 306us/step - loss: 181441.4676\n",
      "Epoch 39/150\n",
      "1168/1168 [==============================] - 0s 326us/step - loss: 181441.4571\n",
      "Epoch 40/150\n",
      "1168/1168 [==============================] - 0s 309us/step - loss: 181441.4494\n",
      "Epoch 41/150\n",
      "1168/1168 [==============================] - 0s 329us/step - loss: 181441.4452\n",
      "Epoch 42/150\n",
      "1168/1168 [==============================] - 0s 313us/step - loss: 181441.4435\n",
      "Epoch 43/150\n",
      "1168/1168 [==============================] - 0s 322us/step - loss: 181441.4350\n",
      "Epoch 44/150\n",
      "1168/1168 [==============================] - 0s 297us/step - loss: 181441.4229\n",
      "Epoch 45/150\n",
      "1168/1168 [==============================] - 0s 323us/step - loss: 181441.4145\n",
      "Epoch 46/150\n",
      "1168/1168 [==============================] - 0s 289us/step - loss: 181441.4083\n",
      "Epoch 47/150\n",
      "1168/1168 [==============================] - 0s 322us/step - loss: 181441.3947\n",
      "Epoch 48/150\n",
      "1168/1168 [==============================] - 0s 296us/step - loss: 181441.3832\n",
      "Epoch 49/150\n",
      "1168/1168 [==============================] - 0s 292us/step - loss: 181441.3696\n",
      "Epoch 50/150\n",
      "1168/1168 [==============================] - 0s 296us/step - loss: 181441.3526\n",
      "Epoch 51/150\n",
      "1168/1168 [==============================] - 0s 281us/step - loss: 181441.3354\n",
      "Epoch 52/150\n",
      "1168/1168 [==============================] - 0s 296us/step - loss: 181441.3176\n",
      "Epoch 53/150\n",
      "1168/1168 [==============================] - 0s 322us/step - loss: 181441.2949\n",
      "Epoch 54/150\n",
      "1168/1168 [==============================] - 0s 355us/step - loss: 181441.2687\n",
      "Epoch 55/150\n",
      "1168/1168 [==============================] - 0s 356us/step - loss: 181441.2422\n",
      "Epoch 56/150\n",
      "1168/1168 [==============================] - 0s 339us/step - loss: 181441.2061\n",
      "Epoch 57/150\n",
      "1168/1168 [==============================] - 0s 299us/step - loss: 181441.1655\n",
      "Epoch 58/150\n",
      "1168/1168 [==============================] - 0s 292us/step - loss: 181441.1193\n",
      "Epoch 59/150\n",
      "1168/1168 [==============================] - 0s 306us/step - loss: 181441.0630\n",
      "Epoch 60/150\n",
      "1168/1168 [==============================] - 0s 332us/step - loss: 181440.9950\n",
      "Epoch 61/150\n",
      "1168/1168 [==============================] - 0s 345us/step - loss: 181440.9165\n",
      "Epoch 62/150\n",
      "1168/1168 [==============================] - 0s 297us/step - loss: 181440.8143\n",
      "Epoch 63/150\n",
      "1168/1168 [==============================] - 0s 294us/step - loss: 181440.6891\n",
      "Epoch 64/150\n",
      "1168/1168 [==============================] - 0s 302us/step - loss: 181440.5299\n",
      "Epoch 65/150\n",
      "1168/1168 [==============================] - 0s 283us/step - loss: 181440.3234\n",
      "Epoch 66/150\n",
      "1168/1168 [==============================] - 0s 321us/step - loss: 181440.0486\n",
      "Epoch 67/150\n",
      "1168/1168 [==============================] - 0s 283us/step - loss: 181439.6788\n",
      "Epoch 68/150\n",
      "1168/1168 [==============================] - 0s 289us/step - loss: 181439.1528\n",
      "Epoch 69/150\n",
      "1168/1168 [==============================] - 0s 292us/step - loss: 181438.3776\n",
      "Epoch 70/150\n",
      "1168/1168 [==============================] - 0s 288us/step - loss: 181437.1722\n",
      "Epoch 71/150\n",
      "1168/1168 [==============================] - 0s 294us/step - loss: 181435.1415\n",
      "Epoch 72/150\n",
      "1168/1168 [==============================] - 0s 294us/step - loss: 181431.3275\n",
      "Epoch 73/150\n",
      "1168/1168 [==============================] - 0s 290us/step - loss: 181422.8250\n",
      "Epoch 74/150\n",
      "1168/1168 [==============================] - 0s 293us/step - loss: 181396.7947\n",
      "Epoch 75/150\n",
      "1168/1168 [==============================] - 0s 289us/step - loss: 181207.7213\n",
      "Epoch 76/150\n",
      "1168/1168 [==============================] - 0s 289us/step - loss: 103555.2152\n",
      "Epoch 77/150\n",
      "1168/1168 [==============================] - 0s 280us/step - loss: 30866.2702\n",
      "Epoch 78/150\n",
      "1168/1168 [==============================] - 0s 320us/step - loss: 26499.5911\n",
      "Epoch 79/150\n",
      "1168/1168 [==============================] - 0s 312us/step - loss: 23807.3896\n",
      "Epoch 80/150\n",
      "1168/1168 [==============================] - 0s 330us/step - loss: 21929.5681\n",
      "Epoch 81/150\n",
      "1168/1168 [==============================] - 0s 310us/step - loss: 19999.6694\n",
      "Epoch 82/150\n",
      "1168/1168 [==============================] - 0s 299us/step - loss: 19392.0406\n",
      "Epoch 83/150\n",
      "1168/1168 [==============================] - 0s 295us/step - loss: 17883.0007\n",
      "Epoch 84/150\n",
      "1168/1168 [==============================] - 0s 283us/step - loss: 16792.0798\n",
      "Epoch 85/150\n",
      "1168/1168 [==============================] - 0s 283us/step - loss: 16616.3899\n",
      "Epoch 86/150\n",
      "1168/1168 [==============================] - 0s 293us/step - loss: 15979.3462\n",
      "Epoch 87/150\n",
      "1168/1168 [==============================] - 0s 331us/step - loss: 16019.2758\n",
      "Epoch 88/150\n",
      "1168/1168 [==============================] - 0s 340us/step - loss: 15585.3545\n",
      "Epoch 89/150\n",
      "1168/1168 [==============================] - 0s 296us/step - loss: 15641.1925\n",
      "Epoch 90/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168/1168 [==============================] - 0s 282us/step - loss: 15473.9240\n",
      "Epoch 91/150\n",
      "1168/1168 [==============================] - 0s 281us/step - loss: 15218.4492\n",
      "Epoch 92/150\n",
      "1168/1168 [==============================] - 0s 283us/step - loss: 15176.0289\n",
      "Epoch 93/150\n",
      "1168/1168 [==============================] - 0s 284us/step - loss: 15202.3111\n",
      "Epoch 94/150\n",
      "1168/1168 [==============================] - 0s 282us/step - loss: 15094.6491\n",
      "Epoch 95/150\n",
      "1168/1168 [==============================] - 0s 283us/step - loss: 14995.0864\n",
      "Epoch 96/150\n",
      "1168/1168 [==============================] - 0s 282us/step - loss: 15020.9862\n",
      "Epoch 97/150\n",
      "1168/1168 [==============================] - 0s 268us/step - loss: 15000.1116\n",
      "Epoch 98/150\n",
      "1168/1168 [==============================] - 0s 279us/step - loss: 14930.2598\n",
      "Epoch 99/150\n",
      "1168/1168 [==============================] - 0s 284us/step - loss: 14959.6838\n",
      "Epoch 100/150\n",
      "1168/1168 [==============================] - 0s 287us/step - loss: 14939.4432\n",
      "Epoch 101/150\n",
      "1168/1168 [==============================] - 0s 281us/step - loss: 14926.6455\n",
      "Epoch 102/150\n",
      "1168/1168 [==============================] - 0s 283us/step - loss: 14917.6610\n",
      "Epoch 103/150\n",
      "1168/1168 [==============================] - 0s 285us/step - loss: 14904.0796\n",
      "Epoch 104/150\n",
      "1168/1168 [==============================] - 0s 277us/step - loss: 14907.8119\n",
      "Epoch 105/150\n",
      "1168/1168 [==============================] - 0s 283us/step - loss: 14899.1072\n",
      "Epoch 106/150\n",
      "1168/1168 [==============================] - 0s 281us/step - loss: 14893.3438\n",
      "Epoch 107/150\n",
      "1168/1168 [==============================] - 0s 283us/step - loss: 14891.2954\n",
      "Epoch 108/150\n",
      "1168/1168 [==============================] - 0s 284us/step - loss: 14887.4640\n",
      "Epoch 109/150\n",
      "1168/1168 [==============================] - 0s 280us/step - loss: 14885.5131\n",
      "Epoch 110/150\n",
      "1168/1168 [==============================] - 0s 312us/step - loss: 14882.7256\n",
      "Epoch 111/150\n",
      "1168/1168 [==============================] - 0s 288us/step - loss: 14880.3098\n",
      "Epoch 112/150\n",
      "1168/1168 [==============================] - 0s 282us/step - loss: 14878.5390\n",
      "Epoch 113/150\n",
      "1168/1168 [==============================] - 0s 302us/step - loss: 14875.4637\n",
      "Epoch 114/150\n",
      "1168/1168 [==============================] - 0s 286us/step - loss: 14874.5037\n",
      "Epoch 115/150\n",
      "1168/1168 [==============================] - 0s 286us/step - loss: 14872.8841\n",
      "Epoch 116/150\n",
      "1168/1168 [==============================] - 0s 290us/step - loss: 14871.3898\n",
      "Epoch 117/150\n",
      "1168/1168 [==============================] - 0s 284us/step - loss: 14870.0265\n",
      "Epoch 118/150\n",
      "1168/1168 [==============================] - 0s 284us/step - loss: 14868.3731\n",
      "Epoch 119/150\n",
      "1168/1168 [==============================] - 0s 327us/step - loss: 14867.2783\n",
      "Epoch 120/150\n",
      "1168/1168 [==============================] - 0s 330us/step - loss: 14865.9243\n",
      "Epoch 121/150\n",
      "1168/1168 [==============================] - 0s 295us/step - loss: 14864.6782\n",
      "Epoch 122/150\n",
      "1168/1168 [==============================] - 0s 305us/step - loss: 14863.3791\n",
      "Epoch 123/150\n",
      "1168/1168 [==============================] - 0s 318us/step - loss: 14862.2098\n",
      "Epoch 124/150\n",
      "1168/1168 [==============================] - 0s 305us/step - loss: 14861.0858\n",
      "Epoch 125/150\n",
      "1168/1168 [==============================] - 0s 300us/step - loss: 14859.8540\n",
      "Epoch 126/150\n",
      "1168/1168 [==============================] - 0s 312us/step - loss: 14858.7625\n",
      "Epoch 127/150\n",
      "1168/1168 [==============================] - 0s 301us/step - loss: 14857.5928\n",
      "Epoch 128/150\n",
      "1168/1168 [==============================] - 0s 283us/step - loss: 14856.3527\n",
      "Epoch 129/150\n",
      "1168/1168 [==============================] - 0s 306us/step - loss: 14855.1891\n",
      "Epoch 130/150\n",
      "1168/1168 [==============================] - 0s 302us/step - loss: 14854.1904\n",
      "Epoch 131/150\n",
      "1168/1168 [==============================] - 0s 297us/step - loss: 14853.2651\n",
      "Epoch 132/150\n",
      "1168/1168 [==============================] - 0s 302us/step - loss: 14851.9439\n",
      "Epoch 133/150\n",
      "1168/1168 [==============================] - 0s 285us/step - loss: 14850.8968\n",
      "Epoch 134/150\n",
      "1168/1168 [==============================] - 0s 310us/step - loss: 14849.8241\n",
      "Epoch 135/150\n",
      "1168/1168 [==============================] - 0s 282us/step - loss: 14848.5947\n",
      "Epoch 136/150\n",
      "1168/1168 [==============================] - 0s 299us/step - loss: 14847.4767\n",
      "Epoch 137/150\n",
      "1168/1168 [==============================] - 0s 306us/step - loss: 14846.2238\n",
      "Epoch 138/150\n",
      "1168/1168 [==============================] - 0s 314us/step - loss: 14845.1892\n",
      "Epoch 139/150\n",
      "1168/1168 [==============================] - 0s 301us/step - loss: 14844.0451\n",
      "Epoch 140/150\n",
      "1168/1168 [==============================] - 0s 297us/step - loss: 14842.8777\n",
      "Epoch 141/150\n",
      "1168/1168 [==============================] - 0s 311us/step - loss: 14841.8014\n",
      "Epoch 142/150\n",
      "1168/1168 [==============================] - 0s 336us/step - loss: 14840.6277\n",
      "Epoch 143/150\n",
      "1168/1168 [==============================] - 0s 366us/step - loss: 14839.7855\n",
      "Epoch 144/150\n",
      "1168/1168 [==============================] - 0s 343us/step - loss: 14838.3861\n",
      "Epoch 145/150\n",
      "1168/1168 [==============================] - 0s 330us/step - loss: 14837.3399\n",
      "Epoch 146/150\n",
      "1168/1168 [==============================] - 0s 334us/step - loss: 14836.2723\n",
      "Epoch 147/150\n",
      "1168/1168 [==============================] - 0s 306us/step - loss: 14835.1023\n",
      "Epoch 148/150\n",
      "1168/1168 [==============================] - 0s 308us/step - loss: 14833.9964\n",
      "Epoch 149/150\n",
      "1168/1168 [==============================] - 0s 300us/step - loss: 14832.8884\n",
      "Epoch 150/150\n",
      "1168/1168 [==============================] - 0s 304us/step - loss: 14831.8582\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras.optimizers import SGD, Adadelta, Adam\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Model\n",
    "model = Sequential()\n",
    "model.add(Dense(200, input_dim=X_train.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(100, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(50, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(25, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='normal'))\n",
    "# Compile model\n",
    "model.compile(loss='mean_absolute_error', optimizer=Adadelta())\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168/1168 [==============================] - 0s 90us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14829.329703553081"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation on the test set created by train_test_split\n",
    "model.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAggAAAFNCAYAAABlgZchAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3de5ycZX3//9d7Z3Y2gYQASYBAkIRDIwclyLEeIIoFRAv4FUuoShQs6tdiPfyqUmyhKt8W0WKtimJBDiqHIipaqVJxSamcAgQIJwnHbBKOCZAEkuxuPr8/7mvIze7sZjfZ3fveyfv5eMxj77nu67rn+swkM5+5ruu+RxGBmZmZWV5L0R0wMzOz8nGCYGZmZr04QTAzM7NenCCYmZlZL04QzMzMrBcnCGZmZtaLEwTbrEmaJikkVQdQ98OSbhqJfqXHe6+kRZJWStpvpB63TCTNktRRdD9gcP9WykrSdZLmDHVda05OEGzUkPS4pLWSJvUon5/euKcV07Nh83XgryNiXETcVXRnRkJ6HXcvuh8jTdLFkr66gTqb/NxExLsi4pKhrmvNyQmCjTaPASfW70h6AzC2uO4Mvdw31F2A+zbyGJWh69HosbnGDa/5d2M2JJwg2GhzGXBS7v4c4NJ8BUkTJF0q6VlJT0j6kqSWtK8i6euSnpP0KPDuBm0vlLRU0mJJXx3Ih05u+PlUSUtS+8/l9rdI+qKkRyQ9L+kqSdv2aHuKpCeB/5G0EqgAd0t6JNXbU1K7pBck3SfpmNzxL5Z0vqRfS1oFvD2VfTcNFa+U9L+SdpD0TUnLJT2Yn7rI9W+FpPslvTe378OSbkrP3XJJj0l6V27/tpJ+mGJfLunnuX3vSaM8L0j6g6Q39vEczk2bd6f+npDb9zlJz6Tn9SMbiLu/1/8sST9q8LpV0/3pkuam5+C/JX0nXz/5gKQn07+hM3LHakvP7ZJ0+6aktvzz1yPekLS7pFOBDwCfT3H/ciDPjdL0i6QvSHoK+KGkbST9KsW+PG1PzR2nXdJHB/iaDqbuQJ43G2WcINhocwuwVfqwrAAnAD3fiP4NmADsChxGllDUP1T+CngPsB9wAHB8j7aXAF3A7qnOEcBHB9G/twN7pHZflPTOVP4p4LjUnx2B5cB3erQ9DNgTeEdEjEtl+0bEbpJagV8CvwW2A04DfixpRq79XwJnA+OB+ofRXwBfAiYBa4CbgTvT/auBf8m1fwR4G9lz94/AjyRNye0/GHgotf0acKEkpX2XAVsAe6f+nQcg6U3ARcDHgInA94Fr6x+ceRFxaC7mcRFxZbq/Q+rTTsApwHckbdNP3P29/hvyE+C21NezgA81qPNWYAZwOPAPkvZM5WcAhwAzgX2Bg8ie+35FxAXAj4Gvpbj/vEGd/p6bbclGm04le0//Ybr/OuAV4Nv9PHx/r+lg6g7kebPRJiJ8821U3IDHgXeSven+E3AUcD1QBQKYRvatew2wV67dx4D2tH0D8PHcviNS2yqwfWo7Nrf/ROD3afvDwE199G1aOs7rc2VfAy5M2w8Ah+f2TQE60+PW2+7a45gB7J623wY8BbTk9l8OnJW2LwYu7dH+YuAHufunAQ/k7r8BeKGf53s+cGwu9oW5fVuk/u2QYlkHbNPgGOcDX+lR9hBwWB+P+WrM6f4ssg+5aq7sGeCQRnEP4PU/C/hRg9etSvaB2gVskdv/o3r9XN2puf23AbPT9iPA0bl9RwKP9/Vvp8frezHw1Q38+2/03KwFxvTTZiawPHe/Hfjohl7TwdTd0PPm2+i9ec7KRqPLgLnAdHpML5B9u6kBT+TKniD79gnZt/dFPfbV7QK0AktzX6JaetTfkJ7HfkPu2D+TtC63v5ssKWnUtqcdgUURkW+fj6uv9k/ntl9pcL8+UoGkk4DPkn0QkvblF4Q+Vd+IiJfTczSO7BvssohY3uDxdwHmSDotV1ZL8QzU8xHRlbv/cr7fvDbuDb3+/dmRLI6Xexx75x71nspt5/uyY4PHHUycG+PZiFhdvyNpC7LRm6OA+ijLeEmViOhu0L6v17SRvupOYmDPm40ynmKwUSciniBbrHg0cE2P3c+RfTPfJVf2OmBx2l7Ka9+4XpfbXkT27XNSRGydbltFxN6D6F7PYy/JHftdueNuHRFjImJxrn5/P626BNi5PpfeIK4Nte+XpF2AHwB/DUyMiK2BBUBfw815i4BtJW3dx76ze8S9RURcvrF9bSAf94Ze/1Vk337rdshtLyWLI79/MB9ySxo8bv31f83jSso/Lmz8a9ez3efIpj8OjoitgPrUxEBex421qc+blZQTBButTiGbq1+VL0zfkq4CzpY0Pn3wfZb16xSuAj4laWqax/5iru1Ssjn+b0jaStnCwt0kHTaIfv29pC0k7U02712fK/5e6tMuAJImSzp2EMe9lexD5vOSWiXNAv4cuGIQx+jPlmQfNs+m/n0E2GcgDdPzdh3w3bRIrlVS/YPpB8DHJR2szJaS3i1pfB+He5ps7cBGGcDrPx84VNLrJE0ATs+1fQKYB5wlqSbpT8me44G6HPhSem0nAf+Qe9y7gb0lzZQ0hmyqI28gcQ+kzniykaEXlC2CPXMQ/d8oQ/C8WUk5QbBRKSIeiYh5few+jezD9FGyRWs/IVsoB9kH1m/I3rDvpPcIxElkQ9T3ky0kvJpsjn2gbgQWAr8Dvh4Rv03l/wpcC/xW0gqyxZYHD/SgEbEWOAZ4F9m35O8CJ0XEg4PoW3/Hvx/4BtkixqfJpkb+dxCH+BDZN/cHydYIfDoddx7ZwtBvkz2fC8nms/tyFnCJsjMe/mJQQazX5+sfEdeTJW33AHcAv+rR9gPAnwLPA19NddcM8HG/SvZBeQ9wL9m/r6+mx/0j8GXgv4GHWb+ItO5CYK8U989p7Cw2/Nx8k+y03+fI/o391wD7vqk25XmzklLERo9Kmlmi7CJNjwGtPebLbRSTdCXwYEQM+zfxZuLnrTl4BMHMLJF0YJpWapF0FHAs0Nc3ekv8vDUnn8VgZrbeDmTTThOBDuATsZlc5noT+XlrQp5iMDMzs148xWBmZma9OEEwMzOzXrwGIdl6661j9903n1+ZXbVqFVtuuWXR3Rgxjre5Od7m5niHzx133PFcRExutM8JQrL99tszb15fp9U3n/b2dmbNmlV0N0aM421ujre5Od7hI+mJvvZ5isHMzMx6cYJgZmZmvThBMDMzs168BsHMzAzo7Oyko6OD1atXb7jyMJowYQIPPPDAkB5zzJgxTJ06ldbW1gG3cYJgZmYGdHR0MH78eKZNm4Y0nL+Q3b8VK1YwfnxfP3g6eBHB888/T0dHB9OnTx9wO08xmJmZAatXr2bixImFJgfDQRITJ04c9MiIEwQzM7Ok2ZKDuo2JywmCmZlZSYwbN67oLrzKCYKZmZn14kWKyYq1weW3PTmoNhszELUxo1famEfaQJOHOjp5Zt6iwTRp/DAbEdCIPW+5Ng8s6WL5XR3919+Ino3UaORgn+f7l3ax4u4lG/E4g24y6OetrdrC5PFtTBrfxvbj26hW/D3FrKeI4POf/zzXXXcdkvjSl77ECSecwNKlSznhhBN46aWX6Orq4vzzz+fNb34zp5xyCvPmzUMSJ598Mp/5zGc2uQ9OEJLnVwenX3Nv0d0YWQvuKboHI+ueu4vuwci6+66ie7BBM3femp9/8i1Fd8OsdK655hrmz5/P3XffzXPPPceBBx7IoYceyk9+8hOOPPJIzjjjDLq7u3n55ZeZP38+ixcvZsGCBQC88MILQ9IHJwjJzuNbuOn0wwdcP4hBP0YMvslGPEqWeW7ILbfcwiGHHJJrsxEPtBE27jnY9Of61ltv5eCDD+7nMQZvIM/z0DzO4NvcdtttHHTQgcP+OBsTz8tru3luxRou/sPj3LfkxY04gtnw+8df3sf9S14a0mPuteNWnPnnew+o7k033cSJJ55IpVJh++2357DDDuP222/nwAMP5OSTT6azs5PjjjuOmTNnsuuuu/Loo49y2mmn8e53v5sjjjhiSPrrBCGpCHaYMKboboyYSWNbmLrNFkV3Y8Q8vmUL0yZtPr8G1zGuhd23G7rzqIfDzY8+z11PLi+6G2al1NcXkEMPPZS5c+fyn//5n3zoQx/ib//2bznppJO4++67+c1vfsN3vvMdrrrqKi666KJN7oMTBDMrRGulhbXd64ruhllDA/2mP1wOPfRQvv/97zNnzhyWLVvG3LlzOffcc3niiSfYaaed+Ku/+itWrVrFnXfeydFHH02tVuN973sfu+22Gx/+8IeHpA9OEMysELVqC53dQUQ07bnnZhvrve99LzfffDP77rsvkvja177GDjvswCWXXMK5555La2sr48aN49JLL2Xx4sV85CMfYd26LOH+p3/6pyHpgxMEMytEWzU7e2Ft9zraqpWCe2NWDitXrmTFihVI4txzz+Xcc899zf45c+YwZ86cXu3uvPPOIe/LsJ1fJOkiSc9IWpAru1LS/HR7XNL8VD5N0iu5fd/Ltdlf0r2SFkr6ltJXDUlt6XgLJd0qaVquzRxJD6db72fSzArXWslGDdZ2eZrBrIyGcwThYuDbwKX1gog4ob4t6RtAfgnzIxExs8FxzgdOBW4Bfg0cBVwHnAIsj4jdJc0GzgFOkLQtcCZwANki6zskXRsRXg1lViK1dP2Dzu4ROoXGzAZl2EYQImIusKzRvjQK8BfA5f0dQ9IUYKuIuDmyJZ2XAsel3ccCl6Ttq4HD03GPBK6PiGUpKbieLKkwsxKppWkFjyCYlVNRlzB7G/B0RDycK5su6S5JN0p6WyrbCchf/q4jldX3LQKIiC6y0YiJ+fIGbcysJDzFYGW0Mdc3GQ02Jq6iFimeyGtHD5YCr4uI5yXtD/xc0t40vipvPcq+9vXX5jUknUo2fcHkyZNpb28fWO+bwMqVKx1vExsN8T6ypAuAm26+hR3Hbdp3ldEQ71ByvMNj3LhxdHR0MGHChELPrOnu7mbFihVDdryI4MUXX2TVqlWDeh5HPEGQVAX+D7B/vSwi1gBr0vYdkh4B/oTs2//UXPOpQP0C8x3AzkBHOuYEsimNDmBWjzbtjfoSERcAFwDMmDEjZs2a1ahaU2pvb8fxNq/REO/qBUvhnjuZ+aYD2GvHrTbpWKMh3qHkeIdHZ2cnHR0dLF68eNgfqz+rV69mzJihvXDfmDFj2HfffWltbR1wmyJGEN4JPBgRr04dSJoMLIuIbkm7AnsAj0bEMkkrJB0C3AqcBPxbanYtMAe4GTgeuCEiQtJvgP8naZtU7wjg9BGJzMwGrLWy/jRHszJobW1l+vTpRXeD9vZ29ttvv6K7MXwJgqTLyb7JT5LUAZwZERcCs+m9OPFQ4MuSuoBu4OMRUV/g+AmyMyLGkp29cF0qvxC4TNJCspGD2QApqfgKcHuq9+XcscysJGrV+lkMThDMymjYEoSIOLGP8g83KPsp8NM+6s8D9mlQvhp4fx9tLgI2/ULUZjZs6qc5epGiWTn5h9jNrBCtVScIZmXmBMHMClHzGgSzUnOCYGaFaPMIglmpOUEws0K0VrxI0azMnCCYWSFqHkEwKzUnCGZWiFrVaxDMyswJgpkVotWnOZqVmhMEMytEm0cQzErNCYKZFcIjCGbl5gTBzApRaRGVFvksBrOScoJgZoWpVVo8gmBWUk4QzKwwtaoTBLOycoJgZoVprbSwtjuK7oaZNeAEwcwK0+YRBLPScoJgZoWpVVt8mqNZSTlBMLPCtFZEp0cQzErJCYKZFcYjCGbl5QTBzArj0xzNyssJgpkVJjuLwQmCWRk5QTCzwvg6CGbl5QTBzArjKQaz8nKCYGaFqVVb/FsMZiXlBMHMCuOzGMzKywmCmRWm1VMMZqXlBMHMCuMpBrPycoJgZoWpVVpY4xEEs1JygmBmhfFpjmbl5QTBzApTq3iKwayshi1BkHSRpGckLciVnSVpsaT56XZ0bt/pkhZKekjSkbny/SXdm/Z9S5JSeZukK1P5rZKm5drMkfRwus0ZrhjNbNPUqi2sC+hykmBWOsM5gnAxcFSD8vMiYma6/RpA0l7AbGDv1Oa7kiqp/vnAqcAe6VY/5inA8ojYHTgPOCcda1vgTOBg4CDgTEnbDH14ZrapWivZW5BPdTQrn2FLECJiLrBsgNWPBa6IiDUR8RiwEDhI0hRgq4i4OSICuBQ4LtfmkrR9NXB4Gl04Erg+IpZFxHLgehonKmZWsFo1ewvq7IqCe2JmPRWxBuGvJd2TpiDq3+x3Ahbl6nSksp3Sds/y17SJiC7gRWBiP8cys5KpJwhrursL7omZ9VQd4cc7H/gKEOnvN4CTATWoG/2Us5FtXkPSqWTTF0yePJn29vZ+ut5cVq5c6Xib2GiJ99GOTgDm3vQHJo3d+O8royXeoeJ4m1tZ4h3RBCEinq5vS/oB8Kt0twPYOVd1KrAklU9tUJ5v0yGpCkwgm9LoAGb1aNPeR38uAC4AmDFjRsyaNatRtabU3t6O421eoyXe5Xd1wIK72f/Ag5k+acuNPs5oiXeoON7mVpZ4R3SKIa0pqHsvUD/D4VpgdjozYTrZYsTbImIpsELSIWl9wUnAL3Jt6mcoHA/ckNYp/AY4QtI2aQrjiFRmZiVTq2RrkX0tBLPyGbYRBEmXk32TnySpg+zMglmSZpIN+T8OfAwgIu6TdBVwP9AFfDIi6pOSnyA7I2IscF26AVwIXCZpIdnIwex0rGWSvgLcnup9OSIGuljSzEZQayWbEXSCYFY+w5YgRMSJDYov7Kf+2cDZDcrnAfs0KF8NvL+PY10EXDTgzppZIeqLFH2ao1n5+EqKZlaYVxMEjyCYlY4TBDMrTM0XSjIrLScIZlaY9RdKcoJgVjZOEMysMF6DYFZeThDMrDCv/haDRxDMSscJgpkVxmsQzMrLCYKZFabNZzGYlZYTBDMrjKcYzMrLCYKZFebVsxg8xWBWOk4QzKwwvlCSWXk5QTCzwlRb0m8xeATBrHScIJhZYSRRq7Y4QTArIScIZlaotkqLpxjMSsgJgpkVqrXqBMGsjJwgmFmhapUWn8VgVkJOEMysUDWPIJiVkhMEMytUa0VepGhWQk4QzKxQtWqFtV1RdDfMrAcnCGZWKJ/maFZOThDMrFC1iuj0GgSz0nGCYGaF8giCWTk5QTCzQtV8oSSzUnKCYGaFavV1EMxKyQmCmRXK10EwKycnCGZWqFq1hTVOEMxKxwmCmRXKl1o2KycnCGZWKJ/FYFZOThDMrFA+i8GsnIYtQZB0kaRnJC3IlZ0r6UFJ90j6maStU/k0Sa9Imp9u38u12V/SvZIWSvqWJKXyNklXpvJbJU3LtZkj6eF0mzNcMZrZpmuteorBrIyGcwThYuCoHmXXA/tExBuBPwKn5/Y9EhEz0+3jufLzgVOBPdKtfsxTgOURsTtwHnAOgKRtgTOBg4GDgDMlbTOUgZnZ0MnWIATr1vn3GMzKZNgShIiYCyzrUfbbiOhKd28BpvZ3DElTgK0i4uaICOBS4Li0+1jgkrR9NXB4Gl04Erg+IpZFxHKypKRnomJmJVGrZm9DXodgVi5FrkE4Gbgud3+6pLsk3SjpbalsJ6AjV6cjldX3LQJISceLwMR8eYM2ZlYytUr2NuRpBrNyqRbxoJLOALqAH6eipcDrIuJ5SfsDP5e0N6AGzevjkH3t669Nz36cSjZ9weTJk2lvbx9wDKPdypUrHW8TG03xPvFEJwC/n3sTW9Ua/ffdsNEU71BwvM2tLPGOeIKQFg2+Bzg8TRsQEWuANWn7DkmPAH9C9u0/Pw0xFViStjuAnYEOSVVgAtmURgcwq0eb9kZ9iYgLgAsAZsyYEbNmzWpUrSm1t7fjeJvXaIp36W1PwgP3cuDBhzBlwtiNOsZoincoON7mVpZ4R3SKQdJRwBeAYyLi5Vz5ZEmVtL0r2WLERyNiKbBC0iFpfcFJwC9Ss2uB+hkKxwM3pITjN8ARkrZJixOPSGVmVkKt9SmGLi9SNCuTYRtBkHQ52Tf5SZI6yM4sOB1oA65PZyveks5YOBT4sqQuoBv4eETUFzh+guyMiLFkaxbq6xYuBC6TtJBs5GA2QEQsk/QV4PZU78u5Y5lZyaxfpNhdcE/MLG/YEoSIOLFB8YV91P0p8NM+9s0D9mlQvhp4fx9tLgIuGnBnzaww9UWK/j0Gs3LxlRTNrFC1arYwsbPbUwxmZeIEwcwKVatUAHy5ZbOScYJgZoV6dQ2CEwSzUnGCYGaFaq3UpxicIJiViRMEMytUfQTBixTNysUJgpkVqs2/xWBWSk4QzKxQ6y+U5ATBrEycIJhZofxrjmbl5ATBzApVv1CSz2IwKxcnCGZWqNaqf+7ZrIycIJhZoXypZbNycoJgZoXyFINZOTlBMLNCtbSIaos8xWBWMk4QzKxwtWqLRxDMSsYJgpkVrlZt8WmOZiXjBMHMCtdaafEUg1nJOEEws8LVKi0+i8GsZJwgmFnh2rwGwax0nCCYWeE8xWBWPk4QzKxwPovBrHycIJhZ4XwWg1n5OEEws8K1VkRnVxTdDTPLcYJgZoWrVSus8QiCWak4QTCzwtUqXoNgVjZOEMyscLWqf4vBrGycIJhZ4TyCYFY+A0oQJO0mqS1tz5L0KUlbD2/XzGxz4dMczcpnoCMIPwW6Je0OXAhMB34ybL0ys81Ka8WnOZqVzUAThHUR0QW8F/hmRHwGmNJfA0kXSXpG0oJc2baSrpf0cPq7TW7f6ZIWSnpI0pG58v0l3Zv2fUuSUnmbpCtT+a2SpuXazEmP8bCkOQOM0cwK0lateATBrGQGmiB0SjoRmAP8KpW1bqDNxcBRPcq+CPwuIvYAfpfuI2kvYDawd2rzXUmV1OZ84FRgj3SrH/MUYHlE7A6cB5yTjrUtcCZwMHAQcGY+ETGz8vEUg1n5DDRB+Ajwp8DZEfGYpOnAj/prEBFzgWU9io8FLknblwDH5cqviIg1EfEYsBA4SNIUYKuIuDkiAri0R5v6sa4GDk+jC0cC10fEsohYDlxP70TFzEqkfiXF7L+5mZVBdSCVIuJ+4FMA6dv4+Ij45414vO0jYmk65lJJ26XynYBbcvU6Ulln2u5ZXm+zKB2rS9KLwMR8eYM2ZlZCbdXsu8ra7nW0VSsbqG1mI2FACYKkduCYVH8+8KykGyPis0PUDzUoi37KN7bNax9UOpVs+oLJkyfT3t6+wY42i5UrVzreJjba4n3y8U4Abmify9hqo//C/Rtt8W4qx9vcyhLvgBIEYEJEvCTpo8API+JMSfdsxOM9LWlKGj2YAjyTyjuAnXP1pgJLUvnUBuX5Nh2SqsAEsimNDmBWjzbtjToTERcAFwDMmDEjZs2a1ahaU2pvb8fxNq/RFu8Ttcfhofs46JA3M3Fc26Dbj7Z4N5XjbW5liXegaxCq6QP9L1i/SHFjXEu20JH09xe58tnpzITpZIsRb0vTESskHZLWF5zUo039WMcDN6R1Cr8BjpC0TZoOOSKVmVlJ1XJTDGZWDgMdQfgy2Yfs/0bE7ZJ2BR7ur4Gky8m+yU+S1EF2ZsE/A1dJOgV4Eng/QETcJ+kq4H6gC/hkRHSnQ32C7IyIscB16QbZ9Rguk7SQbORgdjrWMklfAW6v9z0iei6WNLMSqVWyBGFNpxMEs7IY6CLF/wD+I3f/UeB9G2hzYh+7Du+j/tnA2Q3K5wH7NChfTUowGuy7CLiov/6ZWXl4BMGsfAZ6qeWpkn6WLnz0tKSfSpq64ZZmZhv26lkMvhaCWWkMdA3CD8nm/HckO2Xwl6nMzGyT1UcQ1jhBMCuNgSYIkyPihxHRlW4XA5OHsV9mthmpeQTBrHQGmiA8J+mDkirp9kHg+eHsmJltPtq8BsGsdAaaIJxMdorjU8BSstMKPzJcnTKzzUutkl090SMIZuUxoAQhIp6MiGMiYnJEbBcRxwH/Z5j7ZmabCU8xmJXPQEcQGhmqyyyb2WZu/WmO3RuoaWYjZVMShMFfMN3MrIFXz2LwhZLMSmNTEgT/LquZDQkvUjQrn36vpChpBY0TAZFd+tjMbJN5DYJZ+fSbIETE+JHqiJltvl79LQYnCGalsSlTDGZmQ6KeIHgEwaw8nCCYWeFaWkRrRV6DYFYiThDMrBRqlRaPIJiViBMEMyuFWtUJglmZOEEws1KoVVtY0+ULJZmVhRMEMysFjyCYlYsTBDMrhbZqxYsUzUrECYKZlYIXKZqVixMEMyuFbA2CEwSzsnCCYGal4DUIZuXiBMHMSqGt2uI1CGYl4gTBzErBaxDMysUJgpmVgqcYzMrFCYKZlYIXKZqVixMEMysFTzGYlYsTBDMrhbZWL1I0KxMnCGZWCrVKxSMIZiUy4gmCpBmS5uduL0n6tKSzJC3OlR+da3O6pIWSHpJ0ZK58f0n3pn3fkqRU3ibpylR+q6RpIx2nmQ2OFymalcuIJwgR8VBEzIyImcD+wMvAz9Lu8+r7IuLXAJL2AmYDewNHAd+VVEn1zwdOBfZIt6NS+SnA8ojYHTgPOGcEQjOzTVBL10GIiKK7YmYUP8VwOPBIRDzRT51jgSsiYk1EPAYsBA6SNAXYKiJujuwd5VLguFybS9L21cDh9dEFMyuntmr2duR1CGblUHSCMBu4PHf/ryXdI+kiSduksp2ARbk6Halsp7Tds/w1bSKiC3gRmDj03TezoVKrpATB0wxmpVAt6oEl1YBjgNNT0fnAV4BIf78BnAw0+uYf/ZSzgX35PpxKNkXB5MmTaW9vH3gAo9zKlSsdbxMbjfE+8UQnAL+fexNb1QY34Dca490Ujre5lSXewhIE4F3AnRHxNED9L4CkHwC/Snc7gJ1z7aYCS1L51Abl+TYdkqrABGBZzw5ExAXABQAzZsyIWbNmbXJQo0V7ezuOt3mNxniX3vYkPHAvBxx0CDtuPXZQbUdjvJvC8Ta3ssRb5BTDieSmF9Kagrr3AgvS9rXA7HRmwnSyxYi3RcRSYIWkQ9L6gpOAX+TazEnbxwM3hFc+mZWapxjMyqWQEQRJWwB/BnwsV/w1STPJpgIer++LiPskXQXcD3QBn4yI7tTmE8DFwFjgunQDuBC4TNJCspGD2cMZj5lturZWL1I0Kx++oAUAABKQSURBVJNCEoSIeJkeiwYj4kP91D8bOLtB+Txgnwblq4H3b3pPzWykeATBrFyKPovBzAzIroMA+AebzErCCYKZlUI9QfAIglk5OEEws1LwhZLMysUJgpmVQq2SXUHdIwhm5eAEwcxKYf0ahO4N1DSzkeAEwcxKwWsQzMrFCYKZlUKbEwSzUnGCYGalUPMiRbNScYJgZqXgKQazcnGCYGalUL+Soi+UZFYOThDMrBR8qWWzcnGCYGal0NIiWivyGgSzknCCYGalUau0eATBrCScIJhZadSqLb5QkllJOEEws9KoVT2CYFYWThDMrDTaqhUnCGYl4QTBzEqjVm3xIkWzknCCYGal4UWKZuXhBMHMSiNbpOgEwawMnCCYWWl4kaJZeThBMLPSaPMaBLPScIJgZqXhNQhm5eEEwcxKw2sQzMrDCYKZlYbXIJiVhxMEMyuNNicIZqXhBMHMSsMXSjIrDycIZlYatYovtWxWFk4QzKw0vAbBrDwKSRAkPS7pXknzJc1LZdtKul7Sw+nvNrn6p0taKOkhSUfmyvdPx1ko6VuSlMrbJF2Zym+VNG2kYzSzwatPMURE0V0x2+wVOYLw9oiYGREHpPtfBH4XEXsAv0v3kbQXMBvYGzgK+K6kSmpzPnAqsEe6HZXKTwGWR8TuwHnAOSMQj5ltorZq9pbkdQhmxSvTFMOxwCVp+xLguFz5FRGxJiIeAxYCB0maAmwVETdH9nXj0h5t6se6Gji8PrpgZuVVq2RvSb4WglnxikoQAvitpDsknZrKto+IpQDp73apfCdgUa5tRyrbKW33LH9Nm4joAl4EJg5DHGY2hGr1EQQnCGaFqxb0uG+JiCWStgOul/RgP3UbffOPfsr7a/PaA2fJyakAkydPpr29vd9ON5OVK1c63iY2WuN9fFEnADf+z/8ycezAv7+M1ng3luNtbmWJt5AEISKWpL/PSPoZcBDwtKQpEbE0TR88k6p3ADvnmk8FlqTyqQ3K8206JFWBCcCyBv24ALgAYMaMGTFr1qyhCXAUaG9vx/E2r9Ea77I7O+C+u9n/wIOZNmnLAbcbrfFuLMfb3MoS74hPMUjaUtL4+jZwBLAAuBaYk6rNAX6Rtq8FZqczE6aTLUa8LU1DrJB0SFpfcFKPNvVjHQ/cEF4WbVZ6NS9SNCuNIkYQtgd+ltYMVoGfRMR/SboduErSKcCTwPsBIuI+SVcB9wNdwCcjojsd6xPAxcBY4Lp0A7gQuEzSQrKRg9kjEZiZbZr6IkWvQTAr3ognCBHxKLBvg/LngcP7aHM2cHaD8nnAPg3KV5MSDDMbPeojCD6Lwax4ZTrN0cw2cz6Lwaw8nCCYWWn4Qklm5eEEwcxKo1bJLpK6prN7AzXNbLg5QTCz0vBZDGbl4QTBzEqjzWsQzErDCYKZlYYXKZqVhxMEMysNTzGYlYcTBDMrDY8gmJWHEwQzKw3/3LNZeThBMLPS8KWWzcrDCYKZlUZLi2ityGsQzErACYKZlUqt0sKaTicIZkVzgmBmpVKrtrC221dSNCuaEwQzK5W2asVrEMxKwAmCmZVKrdriBMGsBJwgmFmpZFMMThDMiuYEwcxKpVbxCIJZGThBMLNSqVVbfKEksxJwgmBmpeI1CGbl4ATBzEqlzSMIZqXgBMHMSsVrEMzKwQmCmZWKz2IwKwcnCGZWKm1eg2BWCk4QzKxUxtYqvPhKJ50eRTArlBMEMyuVd+65PS++0sl/3rO06K6YbdacIJhZqbx9xnbssd04vnfjI0RE0d0x22w5QTCzUmlpER87bDcefGoFN/7x2aK7Y7bZcoJgZqVzzL47MmXCGL534yNFd8Vss+UEwcxKp1Zt4ZS3TueWR5cxf9ELRXfHbLM04gmCpJ0l/V7SA5Luk/Q3qfwsSYslzU+3o3NtTpe0UNJDko7Mle8v6d6071uSlMrbJF2Zym+VNG2k4zSzTTP7oNcxfkyV89sXFt0Vs81SESMIXcDnImJP4BDgk5L2SvvOi4iZ6fZrgLRvNrA3cBTwXUmVVP984FRgj3Q7KpWfAiyPiN2B84BzRiAuMxtC49qqfPStu/Kb+57mF/MXF90ds83OiCcIEbE0Iu5M2yuAB4Cd+mlyLHBFRKyJiMeAhcBBkqYAW0XEzZEtdb4UOC7X5pK0fTVweH10wcxGj//79t04YJdt+Ltr7uXRZ1cW3R2zzYqKPI0oDf3PBfYBPgt8GHgJmEc2yrBc0reBWyLiR6nNhcB1wOPAP0fEO1P524AvRMR7JC0AjoqIjrTvEeDgiHiux+OfSjYCweTJk/e/6qqrhjXeMlm5ciXjxo0ruhsjxvGOXs+/so4z//AK24xp4e8PGUOt0jvXb6Z4B8LxNreRjPftb3/7HRFxQKN91RHpQQOSxgE/BT4dES9JOh/4ChDp7zeAk4FG3/yjn3I2sG99QcQFwAUAM2bMiFmzZg0yitGrvb0dx9u8mi3ebac/w0cuvp3/Xr4t57zvjfQcEGy2eDfE8Ta3ssRbyFkMklrJkoMfR8Q1ABHxdER0R8Q64AfAQal6B7BzrvlUYEkqn9qg/DVtJFWBCcCy4YnGzIbb21+/Hae9Y3eumtfB6dfcS/c6X0DJbLgVcRaDgAuBByLiX3LlU3LV3gssSNvXArPTmQnTyRYj3hYRS4EVkg5JxzwJ+EWuzZy0fTxwQ/iSbGaj2mf/7E847R27c8Xti/ibK+7yDzqZDbMiphjeAnwIuFfS/FT2d8CJkmaSTQU8DnwMICLuk3QVcD/ZGRCfjIju1O4TwMXAWLJ1Cdel8guByyQtJBs5mD3MMZnZMJPE546YwfgxVf7frx9k1Zouzv/g/oxprWy4sZkN2ognCBFxE43XCPy6nzZnA2c3KJ9HtsCxZ/lq4P2b0E0zK6lTD92NcW2tnPHze5lz0W38+5yG66vMbBP5SopmNur85cGv45snzGTeE8v54L/fysq1nkE0G2qFncVgZrYpjp25E1vWqvzfn9zJ3z0T/GHVvbxzz+14826TPO1gNgQ8gmBmo9Y799qen3z0YPbYpoWf37WYky+ex2Hn/p5bH32+6K6ZjXpOEMxsVDtg2ractt8Y7vz7P+OiDx/AFrUqJ/7gFr59w8Os8+mQZhvNCYKZNYUxrRXe8frt+eVpb+U9b9yRr//2j5z4g1tYsPjFortmNio5QTCzpjKurcq/zp7JOe97A398egXv+beb+NTldzF/0Qs889JqOrt9/QSzgfAiRTNrOpI44cDX8a43TOH7Nz7ChTc9xrV3L3l1/y4Tt+Cde27PkXvvwMydt6Z7XdC5bh1jqhVqVX9vMgMnCGbWxLYa08rfHvl65rx5Gnc8vpznVq3luRVruKfjBS67+QkuvOmx19SvVVrYc8et2G/nrZm6zVg6u4O1XeuoVsS2W9bYdssa241vY+dtt2DilrVevwlh1kycIJhZ09tu/Bje9YYprylbuaaL9oee4bFnV1GttNBaEc+uWMNdi17gytsX8Upndx9Hy4xtrTBxXI3WSgvVFtGajlFtcL+1IqotLVQrolbJ/lZbsvLWSktWpyWrW2mB+oXhg/XbdRI8+thaHtIjSCBEPk+R9OqV6LL9ufLcfVK9etv6cV7b9tWdDfWVHvWVOPWXTvWVa0nwwJIult/V0eNYfR9tsHlbf4le3zH2VX/w/epZvOCpLl65d+kG4ujjOR7ka9UfJwhmtlka11blPW/cseG+ru51rFrTTa3aQq3aQmf3OpatWsuyVWt56sXVdCx/mUXLX2H5y2vp6g46u9fR2R10rVtHV3ewtnsdL6/tomtd0Jn2d+XqrC9bf3/QHnpwE5+BUeaeu4vuwciaf2fRPXCCYGbWU7XSwoQt1q9FqLRU2HHrsey49Vj22WnCkD9eRNC1LujqDrojGn6zz+pBEPzP3P/hrW97WxphyJKLV0cbXh19iB4jEfHqb97Xj0OPkYp6jVi/i75+526wP3/XX/31PWvc5tZbb+Xggw/O1e/vcfo41kb0q69WfbXpv199tem94/bb53HAAX1fQnwwx+qvPsAbzul7nxMEM7OCSUrTDQOr31YVW7ZtPm/fj2/ZwrRJWxbdjRHz1PgW9pyyVdHd8GmOZmZm1psTBDMzM+vFCYKZmZn14gTBzMzMenGCYGZmZr04QTAzM7NenCCYmZlZL04QzMzMrBcnCGZmZtaLEwQzMzPrRX1dt3pzI2kF8FDR/RhBk4Dniu7ECHK8zc3xNjfHO3x2iYjJjXZsPhfz3rCHIqLvX8doMpLmOd7m5Xibm+NtbmWJ11MMZmZm1osTBDMzM+vFCcJ6FxTdgRHmeJub421ujre5lSJeL1I0MzOzXjyCYGZmZr04QQAkHSXpIUkLJX2x6P4MNUk7S/q9pAck3Sfpb1L5tpKul/Rw+rtN0X0dKpIqku6S9Kt0v2ljBZC0taSrJT2YXuc/bdaYJX0m/TteIOlySWOaLVZJF0l6RtKCXFmfMUo6Pb1/PSTpyGJ6vfH6iPfc9O/5Hkk/k7R1bt+ojbdRrLl9/5+kkDQpV1ZYrJt9giCpAnwHeBewF3CipL2K7dWQ6wI+FxF7AocAn0wxfhH4XUTsAfwu3W8WfwM8kLvfzLEC/CvwXxHxemBfstibLmZJOwGfAg6IiH2ACjCb5ov1YuCoHmUNY0z/l2cDe6c2303va6PJxfSO93pgn4h4I/BH4HRoingvpnesSNoZ+DPgyVxZobFu9gkCcBCwMCIejYi1wBXAsQX3aUhFxNKIuDNtryD78NiJLM5LUrVLgOOK6eHQkjQVeDfw77nipowVQNJWwKHAhQARsTYiXqB5Y64CYyVVgS2AJTRZrBExF1jWo7ivGI8FroiINRHxGLCQ7H1t1GgUb0T8NiK60t1bgKlpe1TH28drC3Ae8HkgvzCw0FidIGQflIty9ztSWVOSNA3YD7gV2D4ilkKWRADbFdezIfVNsv9o63JlzRorwK7As8AP07TKv0vakiaMOSIWA18n+5a1FHgxIn5LE8baQF8xbg7vYScD16XtpotX0jHA4oi4u8euQmN1ggBqUNaUp3ZIGgf8FPh0RLxUdH+Gg6T3AM9ExB1F92UEVYE3AedHxH7AKkb/EHtDad79WGA6sCOwpaQPFturwjX1e5ikM8imSX9cL2pQbdTGK2kL4AzgHxrtblA2YrE6Qcgysp1z96eSDVk2FUmtZMnBjyPimlT8tKQpaf8U4Jmi+jeE3gIcI+lxsumid0j6Ec0Za10H0BERt6b7V5MlDM0Y8zuBxyLi2YjoBK4B3kxzxtpTXzE27XuYpDnAe4APxPpz8pst3t3IEt670/vWVOBOSTtQcKxOEOB2YA9J0yXVyBaEXFtwn4aUJJHNTz8QEf+S23UtMCdtzwF+MdJ9G2oRcXpETI2IaWSv5Q0R8UGaMNa6iHgKWCRpRio6HLif5oz5SeAQSVukf9eHk62pacZYe+orxmuB2ZLaJE0H9gBuK6B/Q0rSUcAXgGMi4uXcrqaKNyLujYjtImJaet/qAN6U/l8XG2tEbPY34GiyVbKPAGcU3Z9hiO+tZMNS9wDz0+1oYCLZauiH099ti+7rEMc9C/hV2m72WGcC89Jr/HNgm2aNGfhH4EFgAXAZ0NZssQKXk62x6CT7wDilvxjJhqgfIftF2ncV3f8hinch2fx7/T3re80Qb6NYe+x/HJhUhlh9JUUzMzPrxVMMZmZm1osTBDMzM+vFCYKZmZn14gTBzMzMenGCYGZmZr04QTCz0pM0q/7LnGY2MpwgmJmZWS9OEMxsyEj6oKTbJM2X9H1JFUkrJX1D0p2Sfidpcqo7U9Itku6R9LP0OwtI2l3Sf0u6O7XZLR1+nKSrJT0o6cfpSopmNkycIJjZkJC0J3AC8JaImAl0Ax8AtgTujIg3ATcCZ6YmlwJfiIg3Avfmyn8MfCci9iX7nYWlqXw/4NPAXmS/YPmWYQ/KbDNWLboDZtY0Dgf2B25PX+7Hkv2g0DrgylTnR8A1kiYAW0fEjan8EuA/JI0HdoqInwFExGqAdLzbIqIj3Z8PTANuGv6wzDZPThDMbKgIuCQiTn9NofT3Per1d333/qYN1uS2u/H7l9mw8hSDmQ2V3wHHS9oOQNK2knYhe585PtX5S+CmiHgRWC7pban8Q8CNEfES0CHpuHSMNklbjGgUZgY4AzezIRIR90v6EvBbSS1kv1b3SWAVsLekO4AXydYpQPaTxd9LCcCjwEdS+YeA70v6cjrG+0cwDDNL/GuOZjasJK2MiHFF98PMBsdTDGZmZtaLRxDMzMysF48gmJmZWS9OEMzMzKwXJwhmZmbWixMEMzMz68UJgpmZmfXiBMHMzMx6+f8Be5XC94dbfWwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "#plt.gca().set_ylim(0, 1)\n",
    "plt.title('Model performance throughout training')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[159663.7  ],\n",
       "       [346684.1  ],\n",
       "       [117493.62 ],\n",
       "       [171995.   ],\n",
       "       [320309.72 ],\n",
       "       [ 87298.99 ],\n",
       "       [234970.5  ],\n",
       "       [145914.77 ],\n",
       "       [ 88474.1  ],\n",
       "       [151914.67 ],\n",
       "       [143930.77 ],\n",
       "       [120570.555],\n",
       "       [104763.234],\n",
       "       [204149.72 ],\n",
       "       [185321.33 ],\n",
       "       [137421.39 ],\n",
       "       [201983.97 ],\n",
       "       [137532.95 ],\n",
       "       [111433.14 ],\n",
       "       [226099.83 ],\n",
       "       [169512.88 ],\n",
       "       [210898.89 ],\n",
       "       [186632.66 ],\n",
       "       [130248.125],\n",
       "       [203970.16 ],\n",
       "       [151184.03 ],\n",
       "       [188066.38 ],\n",
       "       [107096.195],\n",
       "       [180083.92 ],\n",
       "       [193359.48 ],\n",
       "       [122998.016],\n",
       "       [290986.   ],\n",
       "       [210988.77 ],\n",
       "       [115145.914],\n",
       "       [277849.3  ],\n",
       "       [156388.2  ],\n",
       "       [146792.69 ],\n",
       "       [212336.92 ],\n",
       "       [343551.78 ],\n",
       "       [ 96611.04 ],\n",
       "       [118919.17 ],\n",
       "       [255705.39 ],\n",
       "       [120514.47 ],\n",
       "       [333628.88 ],\n",
       "       [133625.48 ],\n",
       "       [137252.92 ],\n",
       "       [118525.52 ],\n",
       "       [139725.75 ],\n",
       "       [424380.3  ],\n",
       "       [134380.92 ],\n",
       "       [125722.945],\n",
       "       [218080.22 ],\n",
       "       [115432.25 ],\n",
       "       [335927.16 ],\n",
       "       [152029.12 ],\n",
       "       [264142.12 ],\n",
       "       [212705.16 ],\n",
       "       [156825.06 ],\n",
       "       [146958.84 ],\n",
       "       [112135.695],\n",
       "       [ 80650.625],\n",
       "       [159113.31 ],\n",
       "       [310364.03 ],\n",
       "       [256536.92 ],\n",
       "       [280634.8  ],\n",
       "       [220771.72 ],\n",
       "       [104459.09 ],\n",
       "       [346558.94 ],\n",
       "       [111003.93 ],\n",
       "       [174718.84 ],\n",
       "       [117903.11 ],\n",
       "       [129727.62 ],\n",
       "       [109322.7  ],\n",
       "       [ 87332.62 ],\n",
       "       [470131.84 ],\n",
       "       [180649.53 ],\n",
       "       [333438.16 ],\n",
       "       [332102.94 ],\n",
       "       [134722.5  ],\n",
       "       [126293.8  ],\n",
       "       [132118.1  ],\n",
       "       [ 88398.98 ],\n",
       "       [120413.74 ],\n",
       "       [109743.695],\n",
       "       [162523.94 ],\n",
       "       [126273.68 ],\n",
       "       [280461.44 ],\n",
       "       [208535.19 ],\n",
       "       [151697.78 ],\n",
       "       [192463.19 ],\n",
       "       [158424.12 ],\n",
       "       [152851.2  ],\n",
       "       [130870.55 ],\n",
       "       [275758.   ],\n",
       "       [126524.78 ],\n",
       "       [177433.83 ],\n",
       "       [173562.17 ],\n",
       "       [178178.84 ],\n",
       "       [207838.66 ],\n",
       "       [261758.6  ],\n",
       "       [188322.69 ],\n",
       "       [219433.6  ],\n",
       "       [325880.97 ],\n",
       "       [134429.17 ],\n",
       "       [184963.64 ],\n",
       "       [164459.84 ],\n",
       "       [164443.92 ],\n",
       "       [253300.8  ],\n",
       "       [146941.88 ],\n",
       "       [195355.95 ],\n",
       "       [ 65642.49 ],\n",
       "       [113896.16 ],\n",
       "       [159333.48 ],\n",
       "       [144921.19 ],\n",
       "       [213599.53 ],\n",
       "       [129202.29 ],\n",
       "       [110022.41 ],\n",
       "       [118944.04 ],\n",
       "       [132903.95 ],\n",
       "       [333992.06 ],\n",
       "       [137599.92 ],\n",
       "       [153531.05 ],\n",
       "       [177743.5  ],\n",
       "       [180833.83 ],\n",
       "       [195120.66 ],\n",
       "       [134835.06 ],\n",
       "       [238221.42 ],\n",
       "       [ 94035.24 ],\n",
       "       [149087.84 ],\n",
       "       [190550.92 ],\n",
       "       [196848.5  ],\n",
       "       [368692.6  ],\n",
       "       [198628.12 ],\n",
       "       [125434.27 ],\n",
       "       [ 75653.56 ],\n",
       "       [349062.4  ],\n",
       "       [366264.3  ],\n",
       "       [132582.22 ],\n",
       "       [258305.92 ],\n",
       "       [571191.06 ],\n",
       "       [357104.44 ],\n",
       "       [132690.62 ],\n",
       "       [172194.61 ],\n",
       "       [152997.61 ],\n",
       "       [143011.92 ],\n",
       "       [127665.516],\n",
       "       [199863.75 ],\n",
       "       [193723.61 ],\n",
       "       [135076.19 ],\n",
       "       [ 70961.836],\n",
       "       [101396.31 ],\n",
       "       [145652.53 ],\n",
       "       [239068.69 ],\n",
       "       [157999.45 ],\n",
       "       [ 94845.55 ],\n",
       "       [129590.445],\n",
       "       [136243.94 ],\n",
       "       [141544.06 ],\n",
       "       [ 92780.02 ],\n",
       "       [135319.7  ],\n",
       "       [197893.92 ],\n",
       "       [137960.78 ],\n",
       "       [314962.1  ],\n",
       "       [155843.95 ],\n",
       "       [112638.47 ],\n",
       "       [132142.17 ],\n",
       "       [258457.12 ],\n",
       "       [333578.84 ],\n",
       "       [404495.62 ],\n",
       "       [222238.92 ],\n",
       "       [379276.56 ],\n",
       "       [ 86900.77 ],\n",
       "       [111447.99 ],\n",
       "       [160561.33 ],\n",
       "       [332254.9  ],\n",
       "       [124643.914],\n",
       "       [128258.83 ],\n",
       "       [216394.72 ],\n",
       "       [124056.15 ],\n",
       "       [163486.2  ],\n",
       "       [174366.64 ],\n",
       "       [104502.   ],\n",
       "       [125449.31 ],\n",
       "       [164414.53 ],\n",
       "       [282307.75 ],\n",
       "       [148818.64 ],\n",
       "       [309344.25 ],\n",
       "       [250817.03 ],\n",
       "       [191804.89 ],\n",
       "       [ 96644.766],\n",
       "       [124944.6  ],\n",
       "       [107810.58 ],\n",
       "       [146803.11 ],\n",
       "       [172376.88 ],\n",
       "       [203241.98 ],\n",
       "       [190935.27 ],\n",
       "       [229616.1  ],\n",
       "       [ 90433.37 ],\n",
       "       [222979.11 ],\n",
       "       [122065.07 ],\n",
       "       [243828.27 ],\n",
       "       [198539.2  ],\n",
       "       [130642.97 ],\n",
       "       [340960.03 ],\n",
       "       [201090.58 ],\n",
       "       [121523.26 ],\n",
       "       [247657.25 ],\n",
       "       [140915.56 ],\n",
       "       [150901.72 ],\n",
       "       [113094.586],\n",
       "       [264733.3  ],\n",
       "       [147502.47 ],\n",
       "       [110681.74 ],\n",
       "       [164718.36 ],\n",
       "       [218091.28 ],\n",
       "       [266729.34 ],\n",
       "       [220345.5  ],\n",
       "       [145226.22 ],\n",
       "       [127708.91 ],\n",
       "       [123059.58 ],\n",
       "       [138976.56 ],\n",
       "       [237721.33 ],\n",
       "       [201034.7  ],\n",
       "       [108645.26 ],\n",
       "       [227381.67 ],\n",
       "       [162689.69 ],\n",
       "       [ 92949.49 ],\n",
       "       [104095.71 ],\n",
       "       [178167.86 ],\n",
       "       [106286.08 ],\n",
       "       [104424.914],\n",
       "       [174293.42 ],\n",
       "       [123616.28 ],\n",
       "       [138750.5  ],\n",
       "       [252301.66 ],\n",
       "       [139276.58 ],\n",
       "       [203437.61 ],\n",
       "       [155797.11 ],\n",
       "       [251993.27 ],\n",
       "       [126734.59 ],\n",
       "       [122014.99 ],\n",
       "       [284294.16 ],\n",
       "       [242573.33 ],\n",
       "       [413433.1  ],\n",
       "       [188662.62 ],\n",
       "       [118661.4  ],\n",
       "       [141098.23 ],\n",
       "       [181541.78 ],\n",
       "       [150449.94 ],\n",
       "       [ 98117.49 ],\n",
       "       [188342.12 ],\n",
       "       [168649.66 ],\n",
       "       [128618.75 ],\n",
       "       [ 91807.91 ],\n",
       "       [145209.42 ],\n",
       "       [137896.53 ],\n",
       "       [138024.16 ],\n",
       "       [128135.47 ],\n",
       "       [170918.72 ],\n",
       "       [285954.1  ],\n",
       "       [310627.6  ],\n",
       "       [176910.4  ],\n",
       "       [134650.14 ],\n",
       "       [257808.38 ],\n",
       "       [311459.25 ],\n",
       "       [228623.89 ],\n",
       "       [191401.97 ],\n",
       "       [147596.7  ],\n",
       "       [114014.91 ],\n",
       "       [181531.39 ],\n",
       "       [410629.72 ],\n",
       "       [221778.31 ],\n",
       "       [239959.44 ],\n",
       "       [ 95129.54 ],\n",
       "       [ 99829.14 ],\n",
       "       [146892.4  ],\n",
       "       [177559.34 ],\n",
       "       [284087.53 ],\n",
       "       [227002.95 ],\n",
       "       [149066.1  ],\n",
       "       [211886.77 ],\n",
       "       [ 97122.195],\n",
       "       [190890.58 ],\n",
       "       [116598.51 ],\n",
       "       [315023.34 ],\n",
       "       [173819.58 ],\n",
       "       [222290.58 ],\n",
       "       [124321.89 ],\n",
       "       [250812.97 ],\n",
       "       [204070.39 ],\n",
       "       [117598.29 ],\n",
       "       [121636.234]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_predict = model.predict(X_val)\n",
    "y_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17001.601669520547"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_val, y_val_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27419.198806401746\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "root_mean_squared_error = sqrt(mean_squared_error(y_val, y_val_predict))\n",
    "print(root_mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../HousePrices/test.csv', header=0)\n",
    "test = test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/tf2/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/opt/conda/envs/tf2/lib/python3.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "id_col = test['Id'].values.tolist()\n",
    "scale = StandardScaler()\n",
    "X_test = test[Features]\n",
    "X_test = scale.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['Id'] = id_col\n",
    "submission['SalePrice'] = prediction\n",
    "submission.to_csv('prediction_keras_allnum.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>2121</td>\n",
       "      <td>95937.304688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>661</td>\n",
       "      <td>2122</td>\n",
       "      <td>110753.429688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>662</td>\n",
       "      <td>2123</td>\n",
       "      <td>91964.421875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>663</td>\n",
       "      <td>2124</td>\n",
       "      <td>167745.609375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>664</td>\n",
       "      <td>2125</td>\n",
       "      <td>139589.796875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1454</td>\n",
       "      <td>2915</td>\n",
       "      <td>93907.601562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1455</td>\n",
       "      <td>2916</td>\n",
       "      <td>98732.515625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1456</td>\n",
       "      <td>2917</td>\n",
       "      <td>180912.093750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1457</td>\n",
       "      <td>2918</td>\n",
       "      <td>110786.671875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1458</td>\n",
       "      <td>2919</td>\n",
       "      <td>249132.984375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>799 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id      SalePrice\n",
       "660   2121   95937.304688\n",
       "661   2122  110753.429688\n",
       "662   2123   91964.421875\n",
       "663   2124  167745.609375\n",
       "664   2125  139589.796875\n",
       "...    ...            ...\n",
       "1454  2915   93907.601562\n",
       "1455  2916   98732.515625\n",
       "1456  2917  180912.093750\n",
       "1457  2918  110786.671875\n",
       "1458  2919  249132.984375\n",
       "\n",
       "[799 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission[660:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score Kaggle\n",
    "<center> Optimizer Adam (lr=0,001): </center>  \n",
    "Dense 200, 100, 50, 25, 1 : 0.15986  \n",
    "<center> Optimizer Adadelta: </center>  \n",
    "Dense 200, 100, 50, 25, 1 : 0.14182"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
